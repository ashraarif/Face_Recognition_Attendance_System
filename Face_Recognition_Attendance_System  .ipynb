{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50b5708d",
   "metadata": {},
   "source": [
    "# VisionCheck: Face Recognition-Based Attendance System\n",
    "\n",
    "### Presented by **N.Ashra**\n",
    "\n",
    "\n",
    "###  **iPEC Solutions Pvt.Ltd** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d9945b",
   "metadata": {},
   "source": [
    "In today's fast-paced world, traditional methods of attendance tracking often prove to be inefficient and prone to inaccuracies. **VisionCheck** addresses these challenges by utilizing advanced face recognition technology to streamline and automate the attendance process. This system integrates facial recognition algorithms with real-time image processing to accurately record and manage attendance in various settings, such as educational institutions and corporate environments.\n",
    "\n",
    "VisionCheck employs state-of-the-art face recognition techniques using libraries such as **face_recognition** and **OpenCV** to identify and verify individuals. The system captures facial features from images and matches them against a pre-enrolled database of faces to mark attendance. This approach not only reduces the time required for manual attendance but also minimizes errors and enhances security by ensuring that only authorized individuals are recorded.\n",
    "\n",
    "The project focuses on developing a robust and user-friendly interface that allows for seamless integration into existing attendance management systems. Additionally, VisionCheck includes features for real-time monitoring, data analytics, and reporting to provide insights into attendance patterns and trends. By automating attendance tracking, VisionCheck aims to improve efficiency, accuracy, and reliability in attendance management, ultimately contributing to a more streamlined and secure environment."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e4d5c704",
   "metadata": {},
   "source": [
    "# installing dlib \n",
    "!pip install dlib"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8673ccb6",
   "metadata": {},
   "source": [
    "# installing face recognition\n",
    "!pip install face recognition"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7d324ca",
   "metadata": {},
   "source": [
    "# Opencv for some image pre-processing.\n",
    "\n",
    "# installing opencv \n",
    "!pip install opencv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebef4514",
   "metadata": {},
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "664daaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c8489bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgelon_bgr = face_recognition.load_image_file(r\"C:\\Users\\Ashra\\Documents\\PROJECT_ASHRA\\CAPSTONE_PROJECT_24\\Ashra_Project\\Face_Recognition_Attendance_System\\images\\ashra.png\")\n",
    "imgelon_rgb = cv2.cvtColor(imgelon_bgr,cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow('bgr', imgelon_bgr)\n",
    "cv2.imshow('rgb', imgelon_rgb)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef99f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgelon =face_recognition.load_image_file(r\"C:\\Users\\Ashra\\Documents\\PROJECT_ASHRA\\CAPSTONE_PROJECT_24\\Ashra_Project\\Face_Recognition_Attendance_System\\images\\ashra.png\")\n",
    "imgelon = cv2.cvtColor(imgelon,cv2.COLOR_BGR2RGB)\n",
    "#----------Finding face Location for drawing bounding boxes-------\n",
    "face = face_recognition.face_locations(imgelon_rgb)[0]\n",
    "copy = imgelon.copy()\n",
    "#-------------------Drawing the Rectangle-------------------------\n",
    "cv2.rectangle(copy, (face[3], face[0]),(face[1], face[2]), (255,0,255), 2)\n",
    "cv2.imshow('copy', copy)\n",
    "cv2.imshow('ashra',imgelon)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5357a794",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encode = face_recognition.face_encodings(imgelon)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e305a23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True]\n"
     ]
    }
   ],
   "source": [
    "# lets test an image\n",
    "test = face_recognition.load_image_file(r\"C:\\Users\\Ashra\\Documents\\PROJECT_ASHRA\\CAPSTONE_PROJECT_24\\Ashra_Project\\Face_Recognition_Attendance_System\\images\\ashra.png\")\n",
    "test = cv2.cvtColor(test, cv2.COLOR_BGR2RGB)\n",
    "test_encode = face_recognition.face_encodings(test)[0]\n",
    "print(face_recognition.compare_faces([train_encode],test_encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51c8a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f90ef19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/Ashra/Documents/PROJECT_ASHRA\\CAPSTONE_PROJECT_24/Ashra_Project/Face_Recognition_Attendance_System/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d09e2180",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "classNames = []\n",
    "mylist = os.listdir(path)\n",
    "for cl in mylist:\n",
    "    curImg = cv2.imread(f'{path}/{cl}')\n",
    "    images.append(curImg)\n",
    "    classNames.append(os.path.splitext(cl)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfd36f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findEncodings(images):\n",
    "    encodeList = []\n",
    "    for img in images:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        face_encodings = face_recognition.face_encodings(img)\n",
    "        if face_encodings:  # Check if the list is not empty\n",
    "            encoded_face = face_encodings[0]\n",
    "            encodeList.append(encoded_face)\n",
    "    return encodeList\n",
    "\n",
    "encoded_face_train = findEncodings(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a9d81f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def markAttendance(name):\n",
    "    with open('Attendance.csv','r+') as f:\n",
    "        myDataList = f.readlines()\n",
    "        nameList = []\n",
    "        for line in myDataList:\n",
    "            entry = line.split(',')\n",
    "            nameList.append(entry[0])\n",
    "        if name not in nameList:\n",
    "            now = datetime.now()\n",
    "            time = now.strftime('%I:%M:%S:%p')\n",
    "            date = now.strftime('%d-%B-%Y')\n",
    "            f.writelines(f'n{name}, {time}, {date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08e8f0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# take pictures from webcam \n",
    "cap  = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgS = cv2.resize(img, (0,0), None, 0.25,0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "    faces_in_frame = face_recognition.face_locations(imgS)\n",
    "    encoded_faces = face_recognition.face_encodings(imgS, faces_in_frame)\n",
    "    for encode_face, faceloc in zip(encoded_faces,faces_in_frame):\n",
    "        matches = face_recognition.compare_faces(encoded_face_train, encode_face)\n",
    "        faceDist = face_recognition.face_distance(encoded_face_train, encode_face)\n",
    "        matchIndex = np.argmin(faceDist)\n",
    "        print(matchIndex)\n",
    "        if matches[matchIndex]:\n",
    "            name = classNames[matchIndex].upper().lower()\n",
    "            y1,x2,y2,x1 = faceloc\n",
    "            # since we scaled down by 4 times\n",
    "            y1, x2,y2,x1 = y1*4,x2*4,y2*4,x1*4\n",
    "            cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "            cv2.rectangle(img, (x1,y2-35),(x2,y2), (0,255,0), cv2.FILLED)\n",
    "            cv2.putText(img,name, (x1+1,y2-5), cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
    "            markAttendance(name)\n",
    "    cv2.imshow('webcam', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c81483a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254b0101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
